{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjxC3aK1E9ixSCmLllYdyG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaizaAli-Dev/AI-DS-Projects/blob/All-about-AI-and-Data-Science/Checking_Over_and_Underfitting_on_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HQRry_VoZow-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# For tensorboard\n",
        "import pathlib\n",
        "import shutil\n",
        "import tempfile\n",
        "import datetime\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Clear any logs from previous runs\n",
        "#rm -rf ./logs/\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
        "shutil.rmtree(logdir, ignore_errors=True)"
      ],
      "metadata": {
        "id": "DJLPEwnlZ00e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "\n",
        "# Define the CNN model\n",
        "def create_cnn_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add convolutional layers with batch normalization\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "   #\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "   #\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "  #\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Add fully connected layers with dropout\n",
        "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create an instance of the CNN model\n",
        "model = create_cnn_model()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1)\n",
        "\n",
        "# The patience parameter is set to 3 number of epochs or iterations,\n",
        "# The training will terminate to 3\n",
        "# if there is no improvement in the monitor performance measure for X epochs or iterations in a row. It will keep working\n",
        "early_stopping = EarlyStopping(patience=3, restore_best_weights=True)\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Train the model with data augmentation and early stopping\n",
        "history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
        "                    steps_per_epoch=len(X_train) // 32,\n",
        "                    epochs=2,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[early_stopping])\n",
        "# 13 epochs would be better\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_UykmHdZ4R8",
        "outputId": "5b352580-8b94-4dcd-e163-9ca7b7ddafcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 109s 57ms/step - loss: 0.8903 - accuracy: 0.8416 - val_loss: 0.2966 - val_accuracy: 0.9769\n",
            "Epoch 2/2\n",
            " 282/1875 [===>..........................] - ETA: 1:29 - loss: 0.4429 - accuracy: 0.9285"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "metadata": {
        "id": "obu6RD-BaFZG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}